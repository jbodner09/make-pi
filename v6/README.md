# Version 6: REALLY. ARE YOU KIDDING ME???, in `make_pi_6.c`

So, performance on the GPU was... less spectacular than expected.  But!  While I still have access to a supercomputer, there is one more thing I wanted to try.  Since single-threaded performance is still so important, and GPUs actually have really poor single-threaded performance, the obvious option is to just use more CPUs!  I only have a single computer, but the supercomputer can totally hook together multiple CPUs to calculate a single program.  

The way they do this is the Message Passing Interface (MPI).  Overall, the code is structured similar to the GPU solution:  one main thread gathers the results calculated from all the other threads.  One interesting thing to notice is that we no longer need a separate function to do the main calculation in!  In fact, with MPI, there are x copies of the entire process launched.  So, every core calculates everything, start to finish, including the final results.  The parallelism comes from the fact that every process works on different iterations, then the final results are calculated by passing everybody's data to everybody else via an all-gather.  The all-gather isn't really necessary, except to keep each core busier.  

A regular gather would have sufficed, and then only the master process would calculate the final result.  As far as performance is concerned, the all-gather is only slightly slower, but it otherwise makes no difference whatsoever.  The data is passed in separate, contiguous arrays where each separate component of each number is put together, similar to the way data was transferred in the GPU solution.  Using 96 cores on the supercomputer, 10,000,000 iterations only takes 12 seconds!  One other unexpected result was that, since each thread does less work, the result is MORE accurate because there is less chance for error to accumulate on each core!  So, using less cores but the same number of iterations gives a less accurate result!  

Otherwise, the only other difference is that the number of threads is now implied by the way we launch the program.  MPI takes care of launching each individual process, and the argument we pass to the launcher tells how many threads to use.  Essentially, this is just a way for Version 4 (the last non-gimmicky one) to run on more than just the cores available in a single machine, and thus it will also get the best performance.  It's a shame I'll never be able to run it again... 
